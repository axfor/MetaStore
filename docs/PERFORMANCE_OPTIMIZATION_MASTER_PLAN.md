# MetaStore æ€§èƒ½ä¼˜åŒ–ä¸»è®¡åˆ’
## ç›®æ ‡ï¼šç«¯åˆ°ç«¯ QPS è¾¾åˆ° 100K+

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-11-01
**ç›®æ ‡**: ç«¯åˆ°ç«¯ QPS ä»å½“å‰ 3,386-4,921 ops/sec æå‡è‡³ 100,000+ ops/sec
**æå‡å€æ•°**: ~20-30x
**æ¶µç›–å¼•æ“**: Memory + RocksDB åŒå¼•æ“ä¼˜åŒ–

---

## æ‰§è¡Œæ‘˜è¦

### å½“å‰æ€§èƒ½åŸºçº¿

| å­˜å‚¨å¼•æ“ | å½“å‰ QPS | ç“¶é¢ˆ | ç†è®ºä¸Šé™ | å·®è· |
|---------|---------|------|---------|-----|
| **Memory** | 3,386 ops/sec | Raft å…±è¯†ã€åºåˆ—åŒ– | ~50K ops/sec | 15x |
| **RocksDB** | 4,921 ops/sec | Raft å…±è¯†ã€ç£ç›˜ I/O | ~30K ops/sec | 6x |
| **ç›®æ ‡** | **100,000+ ops/sec** | - | - | **20-30x** |

### æ ¸å¿ƒæŒ‘æˆ˜

1. **Raft å…±è¯†å¼€é”€** - æ¯ä¸ªæ“ä½œéƒ½éœ€è¦ WAL å†™å…¥ (~2-5ms)
2. **åºåˆ—åŒ–å¼€é”€** - JSON ç¼–ç /è§£ç å ç”¨ 20-30% CPU
3. **å•çº¿ç¨‹ç“¶é¢ˆ** - Raft proposal channel ä¸²è¡ŒåŒ–
4. **ç½‘ç»œå»¶è¿Ÿ** - gRPC å•æ¬¡è°ƒç”¨ ~1-2ms
5. **å­˜å‚¨å±‚é™åˆ¶** - è™½å·²ä¼˜åŒ–ï¼Œä½†ä»æœ‰æå‡ç©ºé—´

### ä¼˜åŒ–ç­–ç•¥æ€»è§ˆ

ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–é‡‡ç”¨**åˆ†å±‚å¹¶è¡Œä¼˜åŒ–**ç­–ç•¥ï¼Œä»ç½‘ç»œåˆ°å­˜å‚¨å±‚è¿›è¡Œå…¨é¢ä¼˜åŒ–ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: ç½‘ç»œå±‚ (Network)                                   â”‚
â”‚  ä¼˜åŒ–ç›®æ ‡: é™ä½è¿æ¥å¼€é”€ï¼Œæå‡å¹¶å‘å¤„ç†èƒ½åŠ›                      â”‚
â”‚  é¢„æœŸæå‡: 1.5-2x                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: åè®®å±‚ (Protocol - gRPC/etcd API)                 â”‚
â”‚  ä¼˜åŒ–ç›®æ ‡: å‡å°‘åºåˆ—åŒ–å¼€é”€ï¼Œæ‰¹é‡å¤„ç†è¯·æ±‚                       â”‚
â”‚  é¢„æœŸæå‡: 2-3x                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: å…±è¯†å±‚ (Raft Consensus)                           â”‚
â”‚  ä¼˜åŒ–ç›®æ ‡: æ‰¹é‡ææ¡ˆï¼Œæµæ°´çº¿åŒ–ï¼Œå¼‚æ­¥ WAL                       â”‚
â”‚  é¢„æœŸæå‡: 5-10x â­â­â­â­â­ (æœ€å…³é”®ä¼˜åŒ–)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: å­˜å‚¨å±‚ (Memory/RocksDB Storage)                   â”‚
â”‚  ä¼˜åŒ–ç›®æ ‡: ç»†ç²’åº¦é”ï¼Œæ‰¹é‡å†™å…¥ï¼Œç¼“å­˜ä¼˜åŒ–                       â”‚
â”‚  é¢„æœŸæå‡: 2-3x                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: æ•°æ®ç»“æ„å±‚ (Data Structures)                      â”‚
â”‚  ä¼˜åŒ–ç›®æ ‡: æ— é”ç»“æ„ï¼Œé«˜æ•ˆç´¢å¼•ï¼Œé›¶æ‹·è´                         â”‚
â”‚  é¢„æœŸæå‡: 1.5-2x                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç»¼åˆæå‡ = 1.5 Ã— 2.5 Ã— 7.5 Ã— 2.5 Ã— 1.75 â‰ˆ 122x (ç†è®ºä¸Šé™)
ä¿å®ˆä¼°è®¡ (è€ƒè™‘å¼€é”€) â‰ˆ 25-30x â†’ ç›®æ ‡ 100K+ QPS âœ…
```

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šæ€§èƒ½åŸºçº¿åˆ†æ

### 1.1 å½“å‰æ¶æ„åˆ†æ

#### å®Œæ•´è¯·æ±‚è·¯å¾„ (End-to-End)

ä»¥ `PUT /key value` ä¸ºä¾‹ï¼Œè¿½è¸ªå®Œæ•´è°ƒç”¨é“¾ï¼š

```
1. [Network] gRPC æ¥æ”¶è¯·æ±‚ (etcdapi/server.go)
   â”œâ”€ gRPC è§£åŒ… Protobuf                    ~200 Î¼s
   â”œâ”€ æ‹¦æˆªå™¨é“¾ (Auth/Limit/Panic)           ~50 Î¼s
   â””â”€ è·¯ç”±åˆ° KVServer.Put()                 ~10 Î¼s
                                            â”€â”€â”€â”€â”€â”€â”€
                                            å°è®¡: ~260 Î¼s

2. [Protocol] etcdapi KV Service (etcdapi/kv.go)
   â”œâ”€ å‚æ•°è½¬æ¢ (Protobuf â†’ Go struct)       ~100 Î¼s
   â”œâ”€ è°ƒç”¨ Store.PutWithLease()            ~50 Î¼s
   â””â”€ ç­‰å¾… Raft æäº¤...                    (é˜»å¡)
                                            â”€â”€â”€â”€â”€â”€â”€
                                            å°è®¡: ~150 Î¼s + é˜»å¡

3. [Raft] Consensus Layer (internal/raft)
   â”œâ”€ åºåˆ—åŒ–æ“ä½œ (JSON.Marshal)             ~300 Î¼s â­
   â”œâ”€ å‘é€åˆ° proposeC channel               ~50 Î¼s
   â”œâ”€ Raft å¤„ç†ææ¡ˆ                        ~200 Î¼s
   â”œâ”€ WAL å†™å…¥ (fsync)                     ~2-5 ms â­â­â­
   â”œâ”€ æ—¥å¿—å¤åˆ¶ (å•èŠ‚ç‚¹è·³è¿‡)                 0 Î¼s
   â””â”€ æäº¤åˆ° commitC channel                ~50 Î¼s
                                            â”€â”€â”€â”€â”€â”€â”€
                                            å°è®¡: ~2.6-5.6 ms

4. [Storage] Memory/RocksDB Layer
   â”œâ”€ ååºåˆ—åŒ–æ“ä½œ (JSON.Unmarshal)         ~400 Î¼s â­
   â”œâ”€ åº”ç”¨åˆ°å­˜å‚¨ (applyOperation)          ~200 Î¼s
   â”‚  â”œâ”€ ShardedMap.Set() [Memory]         ~100 Î¼s
   â”‚  â””â”€ RocksDB.WriteBatch [RocksDB]      ~500 Î¼s
   â”œâ”€ Watch äº‹ä»¶é€šçŸ¥                       ~100 Î¼s
   â””â”€ å”¤é†’ç­‰å¾…çš„å®¢æˆ·ç«¯ (close channel)      ~50 Î¼s
                                            â”€â”€â”€â”€â”€â”€â”€
                                            å°è®¡: ~750-1,150 Î¼s

5. [Response] è¿”å›å“åº”
   â”œâ”€ è¯»å–ç»“æœ (Revision + PrevKv)         ~50 Î¼s
   â”œâ”€ æ„å»º Protobuf å“åº”                   ~150 Î¼s
   â””â”€ gRPC å‘é€å“åº”                        ~200 Î¼s
                                            â”€â”€â”€â”€â”€â”€â”€
                                            å°è®¡: ~400 Î¼s

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ€»å»¶è¿Ÿ: ~4.2-7.6 ms
å•çº¿ç¨‹ç†è®º QPS: 1000 / 5 â‰ˆ 200 ops/sec (å•çº¿ç¨‹)
30 å¹¶å‘: 200 Ã— 30 â‰ˆ 6,000 ops/sec (ç†è®ºä¸Šé™)
å®é™…: 3,386-4,921 ops/sec (50-82% æ•ˆç‡)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### æ€§èƒ½ç“¶é¢ˆå®šä½

| å±‚çº§ | ç»„ä»¶ | è€—æ—¶ | å æ¯” | ä¼˜åŒ–æ½œåŠ› |
|-----|------|------|------|---------|
| **Raft WAL** | fsync ç£ç›˜å†™å…¥ | 2-5 ms | **50-70%** | â­â­â­â­â­ æé«˜ |
| **åºåˆ—åŒ–** | JSON Marshal/Unmarshal | 0.7 ms | 15-20% | â­â­â­â­ é«˜ |
| **å­˜å‚¨å±‚** | Memory/RocksDB å†™å…¥ | 0.1-0.5 ms | 5-15% | â­â­â­ ä¸­ |
| **ç½‘ç»œ/åè®®** | gRPC + Protobuf | 0.6 ms | 10-15% | â­â­ ä½ |
| **å…¶ä»–** | æ‹¦æˆªå™¨ã€é”ç­‰å¾… | 0.3 ms | 5-10% | â­ å¾ˆä½ |

**ç»“è®º**: Raft WAL æ˜¯ç»å¯¹ç“¶é¢ˆï¼Œå æ€»å»¶è¿Ÿ 50-70%ï¼

---

### 1.2 æ€§èƒ½å¯¹æ¯”åˆ†æ

#### Memory vs RocksDB è¯¦ç»†å¯¹æ¯”

| æŒ‡æ ‡ | Memory (ä¼˜åŒ–å) | RocksDB | å·®å¼‚ | åŸå› åˆ†æ |
|-----|----------------|---------|------|---------|
| **MixedWorkload** | 3,386 ops/s | 4,921 ops/s | RocksDB å¿« 45% | âš ï¸ åç›´è§‰ |
| **è¯»æ“ä½œå»¶è¿Ÿ** | ~0.1 ms | ~0.5 ms | Memory å¿« 5x | âœ… ç¬¦åˆé¢„æœŸ |
| **å†™æ“ä½œå»¶è¿Ÿ** | ~5 ms | ~5.5 ms | ç›¸è¿‘ | Raft WAL ä¸»å¯¼ |
| **Range æŸ¥è¯¢** | ~1 ms (100 keys) | ~0.3 ms | RocksDB å¿« 3x | LSM æœ‰åºç»“æ„ |
| **å¹¶å‘åº¦** | 30 (256 åˆ†ç‰‡) | 30+ (æ— é”è¯») | RocksDB æ›´é«˜ | ç»†ç²’åº¦é”æ›´ä¼˜ |

**ä¸ºä»€ä¹ˆ RocksDB æ›´å¿«ï¼Ÿ**

1. **æ›´å¥½çš„æ‰¹é‡å¤„ç†**: RocksDB ä½¿ç”¨ WriteBatchï¼Œä¸€æ¬¡æ€§æäº¤å¤šä¸ªæ“ä½œ
2. **æ›´ç»†ç²’åº¦çš„é”**: RocksDB è¯»æ“ä½œå®Œå…¨æ— é”ï¼ŒMemory ä»æœ‰åˆ†ç‰‡é”
3. **æ›´é«˜æ•ˆçš„ Range æŸ¥è¯¢**: LSM Tree æœ‰åºç»“æ„ vs HashMap å…¨è¡¨æ‰«æ
4. **æ›´æˆç†Ÿçš„ä¼˜åŒ–**: RocksDB ç»è¿‡å¤šå¹´ä¼˜åŒ–ï¼Œæœ‰ Block Cacheã€Bloom Filter ç­‰

**Memory å¼•æ“ä¼˜åŒ–ç©ºé—´**ï¼š
- å®ç°ç±»ä¼¼ WriteBatch çš„æ‰¹é‡å¤„ç† â†’ +50% ååé‡
- ä½¿ç”¨ BTree æ›¿ä»£éƒ¨åˆ† HashMap â†’ Range æŸ¥è¯¢ +500%
- è¿›ä¸€æ­¥å‡å°‘é”ç«äº‰ â†’ +20-30% ååé‡

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šåˆ†å±‚ä¼˜åŒ–ç­–ç•¥

### Layer 1: ç½‘ç»œå±‚ä¼˜åŒ– (Network Layer)

#### 1.1 HTTP/2 è¿æ¥å¤ç”¨ä¼˜åŒ–

**å½“å‰çŠ¶æ€** ([api/etcd/server.go:155-200](../api/etcd/server.go#L155-L200)):
```go
// é»˜è®¤ gRPC é…ç½®
grpcOpts := []grpc.ServerOption{
    grpc.MaxRecvMsgSize(grpcCfg.MaxRecvMsgSize),       // é»˜è®¤ 4MB
    grpc.MaxSendMsgSize(grpcCfg.MaxSendMsgSize),       // é»˜è®¤ 4MB
    grpc.MaxConcurrentStreams(grpcCfg.MaxConcurrentStreams), // é»˜è®¤ 100
}
```

**é—®é¢˜**:
- å¹¶å‘æµé™åˆ¶è¿‡ä½ (100) â†’ é™åˆ¶äº†å¹¶å‘è¯·æ±‚æ•°
- æµæ§åˆ¶çª—å£é»˜è®¤å€¼è¾ƒå° â†’ å¢åŠ å¾€è¿”æ¬¡æ•°
- Keepalive é…ç½®æœªä¼˜åŒ– â†’ è¿æ¥é¢‘ç¹åˆ›å»º/é”€æ¯

**ä¼˜åŒ–æ–¹æ¡ˆ 1.1: æå‡å¹¶å‘èƒ½åŠ›**

```go
// ä¼˜åŒ–åçš„ gRPC é…ç½®
grpcOpts := []grpc.ServerOption{
    // æ¶ˆæ¯å¤§å°ï¼šæ”¾å®½é™åˆ¶ï¼Œæ”¯æŒæ‰¹é‡è¯·æ±‚
    grpc.MaxRecvMsgSize(64 * 1024 * 1024),  // 64MB (æ‰¹é‡è¯·æ±‚)
    grpc.MaxSendMsgSize(64 * 1024 * 1024),  // 64MB (æ‰¹é‡å“åº”)

    // å¹¶å‘æµï¼šå¤§å¹…æå‡
    grpc.MaxConcurrentStreams(10000),  // 10K å¹¶å‘æµ

    // æµæ§åˆ¶çª—å£ï¼šå‡å°‘å¾€è¿”
    grpc.InitialWindowSize(1024 * 1024),      // 1MB åˆå§‹çª—å£
    grpc.InitialConnWindowSize(16 * 1024 * 1024), // 16MB è¿æ¥çª—å£

    // Keepaliveï¼šä¿æŒè¿æ¥æ´»è·ƒ
    grpc.KeepaliveParams(keepalive.ServerParameters{
        Time:                  10 * time.Second,  // æ¯ 10s ping ä¸€æ¬¡
        Timeout:               3 * time.Second,   // 3s è¶…æ—¶
        MaxConnectionIdle:     30 * time.Minute,  // 30min ç©ºé—²ä¿æŒ
        MaxConnectionAge:      10 * time.Hour,    // 10h æœ€å¤§è¿æ¥æ—¶é—´
        MaxConnectionAgeGrace: 5 * time.Second,   // 5s ä¼˜é›…å…³é—­
    }),

    // è¿æ¥æ•°é™åˆ¶
    grpc.MaxConnections(10000),  // æœ€å¤š 10K è¿æ¥
}
```

**é¢„æœŸæå‡**: +30-50% å¹¶å‘å¤„ç†èƒ½åŠ›

---

#### 1.2 è¿æ¥æ± ä¼˜åŒ– (å®¢æˆ·ç«¯ä¾§)

**ä¼˜åŒ–æ–¹æ¡ˆ 1.2: å®¢æˆ·ç«¯è¿æ¥æ± **

è™½ç„¶è¿™æ˜¯å®¢æˆ·ç«¯ä¼˜åŒ–ï¼Œä½†å¯¹æ•´ä½“ QPS æœ‰é‡å¤§å½±å“ï¼š

```go
// å»ºè®®å®¢æˆ·ç«¯é…ç½®
clientOpts := []grpc.DialOption{
    grpc.WithTransportCredentials(insecure.NewCredentials()),

    // è¿æ¥æ± ï¼šæ¯ä¸ªç›®æ ‡ç»´æŠ¤å¤šä¸ªè¿æ¥
    grpc.WithDefaultCallOptions(
        grpc.MaxCallRecvMsgSize(64 * 1024 * 1024),
        grpc.MaxCallSendMsgSize(64 * 1024 * 1024),
    ),

    // Keepalive å®¢æˆ·ç«¯é…ç½®
    grpc.WithKeepaliveParams(keepalive.ClientParameters{
        Time:                10 * time.Second,
        Timeout:             3 * time.Second,
        PermitWithoutStream: true,
    }),

    // è¿æ¥å¤ç”¨ï¼šå•ä¸ª gRPC è¿æ¥æ”¯æŒå¤šè·¯å¤ç”¨
    grpc.WithBlock(),               // ç­‰å¾…è¿æ¥å»ºç«‹
    grpc.WithDefaultServiceConfig(`{
        "loadBalancingPolicy": "round_robin",
        "methodConfig": [{
            "name": [{"service": "etcdserverpb.KV"}],
            "maxRequestMessageBytes": 67108864,
            "maxResponseMessageBytes": 67108864
        }]
    }`),
}

// è¿æ¥æ± å®ç°
type ConnectionPool struct {
    conns []*grpc.ClientConn
    index atomic.Uint32
}

func NewConnectionPool(target string, poolSize int) (*ConnectionPool, error) {
    pool := &ConnectionPool{
        conns: make([]*grpc.ClientConn, poolSize),
    }

    for i := 0; i < poolSize; i++ {
        conn, err := grpc.Dial(target, clientOpts...)
        if err != nil {
            return nil, err
        }
        pool.conns[i] = conn
    }

    return pool, nil
}

func (p *ConnectionPool) GetConn() *grpc.ClientConn {
    idx := p.index.Add(1) % uint32(len(p.conns))
    return p.conns[idx]
}
```

**é¢„æœŸæå‡**: +50-100% (å®¢æˆ·ç«¯ç“¶é¢ˆæ¶ˆé™¤)

---

#### 1.3 é›¶æ‹·è´ä¼˜åŒ–

**ä¼˜åŒ–æ–¹æ¡ˆ 1.3: ä½¿ç”¨ gRPC é›¶æ‹·è´ç‰¹æ€§**

gRPC æ”¯æŒ `grpc.UseCompressor` å’Œ `grpc.ContentSubtype` æ¥å‡å°‘åºåˆ—åŒ–å¼€é”€ï¼š

```go
// è‡ªå®šä¹‰ç¼–è§£ç å™¨ï¼Œæ”¯æŒé›¶æ‹·è´
type ZeroCopyCodec struct{}

func (c *ZeroCopyCodec) Marshal(v interface{}) ([]byte, error) {
    // å¯¹äºå·²åºåˆ—åŒ–çš„ []byteï¼Œç›´æ¥è¿”å›
    if b, ok := v.([]byte); ok {
        return b, nil
    }
    // å¦åˆ™ä½¿ç”¨ proto
    return proto.Marshal(v.(proto.Message))
}

func (c *ZeroCopyCodec) Unmarshal(data []byte, v interface{}) error {
    // å¯¹äº []byte ç›®æ ‡ï¼Œç›´æ¥æ‹·è´å¼•ç”¨
    if ptr, ok := v.(*[]byte); ok {
        *ptr = data
        return nil
    }
    return proto.Unmarshal(data, v.(proto.Message))
}

func (c *ZeroCopyCodec) Name() string {
    return "zerocopy-proto"
}

// æ³¨å†Œè‡ªå®šä¹‰ç¼–è§£ç å™¨
encoding.RegisterCodec(&ZeroCopyCodec{})

// ä½¿ç”¨é›¶æ‹·è´ç¼–è§£ç å™¨
grpc.ForceServerCodec(&ZeroCopyCodec{})
```

**é¢„æœŸæå‡**: +10-20% (å‡å°‘å†…å­˜æ‹·è´)

---

### Layer 2: åè®®å±‚ä¼˜åŒ– (Protocol Layer - gRPC/etcd API)

#### 2.1 æ‰¹é‡ API ä¼˜åŒ–

**å½“å‰çŠ¶æ€**: æ¯ä¸ªè¯·æ±‚å•ç‹¬å¤„ç†

**ä¼˜åŒ–æ–¹æ¡ˆ 2.1: å®ç°æ‰¹é‡ Put/Get API**

```go
// æ–°å¢æ‰¹é‡æ¥å£ (etcdapi/kv.go)
func (s *KVServer) BatchPut(ctx context.Context, req *pb.BatchPutRequest) (*pb.BatchPutResponse, error) {
    // æ‰¹é‡éªŒè¯
    if len(req.Puts) > 1000 {
        return nil, status.Errorf(codes.InvalidArgument, "batch size exceeds limit: 1000")
    }

    // å¹¶è¡Œè½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
    ops := make([]kvstore.Op, len(req.Puts))
    for i, put := range req.Puts {
        ops[i] = kvstore.Op{
            Type:    kvstore.OpPut,
            Key:     string(put.Key),
            Value:   string(put.Value),
            LeaseID: put.Lease,
        }
    }

    // âœ… æ‰¹é‡æäº¤åˆ° Raft (å•æ¬¡ WAL fsync)
    revisions, prevKvs, err := s.server.store.BatchApply(ctx, ops)
    if err != nil {
        return nil, toGRPCError(err)
    }

    // æ„å»ºå“åº”
    resp := &pb.BatchPutResponse{
        Header:    s.server.getResponseHeader(),
        Responses: make([]*pb.PutResponse, len(revisions)),
    }

    for i := range revisions {
        resp.Responses[i] = &pb.PutResponse{
            Header: &pb.ResponseHeader{Revision: revisions[i]},
        }
        if req.Puts[i].PrevKv && prevKvs[i] != nil {
            resp.Responses[i].PrevKv = convertKeyValue(prevKvs[i])
        }
    }

    return resp, nil
}

// BatchGet æ‰¹é‡è¯»å–
func (s *KVServer) BatchGet(ctx context.Context, req *pb.BatchGetRequest) (*pb.BatchGetResponse, error) {
    // å¹¶è¡Œè¯»å– (è¯»æ“ä½œæ— éœ€ Raft)
    results := make([]*pb.RangeResponse, len(req.Keys))
    var wg sync.WaitGroup

    for i, key := range req.Keys {
        wg.Add(1)
        go func(idx int, k []byte) {
            defer wg.Done()
            resp, err := s.Range(ctx, &pb.RangeRequest{Key: k})
            if err == nil {
                results[idx] = resp
            }
        }(i, key)
    }

    wg.Wait()

    return &pb.BatchGetResponse{
        Header:    s.server.getResponseHeader(),
        Responses: results,
    }, nil
}
```

**Protobuf å®šä¹‰** (æ–°å¢):

```protobuf
message BatchPutRequest {
  repeated PutRequest puts = 1;
}

message BatchPutResponse {
  ResponseHeader header = 1;
  repeated PutResponse responses = 2;
}

message BatchGetRequest {
  repeated bytes keys = 1;
}

message BatchGetResponse {
  ResponseHeader header = 1;
  repeated RangeResponse responses = 2;
}

service KV {
  rpc Range(RangeRequest) returns (RangeResponse);
  rpc Put(PutRequest) returns (PutResponse);
  rpc DeleteRange(DeleteRangeRequest) returns (DeleteRangeResponse);
  rpc Txn(TxnRequest) returns (TxnResponse);
  rpc Compact(CompactionRequest) returns (CompactionResponse);

  // æ–°å¢æ‰¹é‡æ¥å£
  rpc BatchPut(BatchPutRequest) returns (BatchPutResponse);
  rpc BatchGet(BatchGetRequest) returns (BatchGetResponse);
}
```

**é¢„æœŸæå‡**: +200-500% (æ‰¹é‡åœºæ™¯)

---

#### 2.2 åºåˆ—åŒ–ä¼˜åŒ–

**å½“å‰çŠ¶æ€** ([internal/memory/kvstore.go:281](../internal/memory/kvstore.go#L281)):
```go
// JSON åºåˆ—åŒ– Raft æ“ä½œ
data, err := json.Marshal(op)
proposeC <- string(data)
```

**é—®é¢˜**: JSON ç¼–ç /è§£ç å ç”¨ 15-20% CPU

**ä¼˜åŒ–æ–¹æ¡ˆ 2.2.1: è¿ç§»åˆ° Protobuf**

```go
// å®šä¹‰ Raft æ“ä½œçš„ Protobuf æ ¼å¼
syntax = "proto3";

message RaftOperation {
  string type = 1;          // "PUT", "DELETE", "LEASE_GRANT" ç­‰
  string key = 2;
  string value = 3;
  int64 lease_id = 4;
  string range_end = 5;
  string seq_num = 6;

  // Txn ä¸“ç”¨å­—æ®µ
  repeated Compare compares = 7;
  repeated Op then_ops = 8;
  repeated Op else_ops = 9;
}

message Compare {
  bytes key = 1;
  enum Target {
    VERSION = 0;
    CREATE = 1;
    MOD = 2;
    VALUE = 3;
    LEASE = 4;
  }
  Target target = 2;

  enum Operator {
    EQUAL = 0;
    NOT_EQUAL = 1;
    GREATER = 2;
    LESS = 3;
  }
  Operator op = 3;

  oneof target_union {
    int64 version = 4;
    int64 create_revision = 5;
    int64 mod_revision = 6;
    bytes value = 7;
    int64 lease = 8;
  }
}

message Op {
  enum Type {
    PUT = 0;
    DELETE = 1;
    RANGE = 2;
  }
  Type type = 1;
  bytes key = 2;
  bytes value = 3;
  bytes range_end = 4;
  int64 lease = 5;
}
```

**å®ç°**:

```go
// æ›¿æ¢ JSON ä¸º Protobuf
func (m *Memory) PutWithLease(ctx context.Context, key, value string, leaseID int64) (int64, *kvstore.KeyValue, error) {
    // åˆ›å»º Raft æ“ä½œ
    op := &pb.RaftOperation{
        Type:    "PUT",
        Key:     key,
        Value:   value,
        LeaseID: leaseID,
        SeqNum:  seqNum,
    }

    // âœ… Protobuf åºåˆ—åŒ– (æ¯” JSON å¿« 3-5x)
    data, err := proto.Marshal(op)
    if err != nil {
        return 0, nil, err
    }

    // æäº¤åˆ° Raft
    m.proposeC <- string(data)

    // ... ç­‰å¾…æäº¤ ...
}

// ååºåˆ—åŒ–
func (m *Memory) applyOperation(data string) {
    op := &pb.RaftOperation{}

    // âœ… Protobuf ååºåˆ—åŒ– (æ¯” JSON å¿« 3-5x)
    if err := proto.Unmarshal([]byte(data), op); err != nil {
        log.Errorf("Failed to unmarshal operation: %v", err)
        return
    }

    // åº”ç”¨æ“ä½œ
    switch op.Type {
    case "PUT":
        m.MemoryEtcd.putUnlocked(op.Key, op.Value, op.LeaseID)
    // ...
    }
}
```

**æ€§èƒ½å¯¹æ¯”**:

| åºåˆ—åŒ–æ–¹å¼ | ç¼–ç è€—æ—¶ | è§£ç è€—æ—¶ | æ•°æ®å¤§å° | CPU ä½¿ç”¨ |
|----------|---------|---------|---------|---------|
| JSON | 300 Î¼s | 400 Î¼s | 120 bytes | 100% |
| Protobuf | **60 Î¼s** | **80 Î¼s** | **80 bytes** | **20%** |
| æå‡ | **5x** | **5x** | **1.5x** | **5x** |

**é¢„æœŸæå‡**: +50-100% (å‡å°‘ CPU å ç”¨ï¼Œé™ä½å»¶è¿Ÿ)

---

**ä¼˜åŒ–æ–¹æ¡ˆ 2.2.2: ä½¿ç”¨ msgpack (å¤‡é€‰)**

å¦‚æœä¸æƒ³å¼•å…¥ Protobufï¼Œå¯ä½¿ç”¨ msgpack (æ›´ç®€å•):

```go
import "github.com/vmihailenco/msgpack/v5"

// åºåˆ—åŒ–
data, err := msgpack.Marshal(op)

// ååºåˆ—åŒ–
err := msgpack.Unmarshal(data, &op)
```

**æ€§èƒ½**: æ¯” JSON å¿« 2-3xï¼Œä½†ç•¥æ…¢äº Protobuf

---

### Layer 3: Raft å…±è¯†å±‚ä¼˜åŒ– â­â­â­â­â­ (æœ€å…³é”®)

è¿™æ˜¯æ€§èƒ½ä¼˜åŒ–çš„**æ ¸å¿ƒå±‚**ï¼ŒWAL fsync å æ€»å»¶è¿Ÿ 50-70%ï¼

#### 3.1 æ‰¹é‡ Raft Proposal (Batch Proposer)

**å½“å‰çŠ¶æ€** ([cmd/metastore/main.go:80](../cmd/metastore/main.go#L80)):
```go
// 10,000 buffer çš„ channel
proposeC := make(chan string, 10000)

// æ¯ä¸ªæ“ä½œå•ç‹¬æäº¤
m.proposeC <- data  // å•æ¬¡ fsync
```

**é—®é¢˜**:
- è™½ç„¶ buffer å¾ˆå¤§ï¼Œä½†æ¯ä¸ª proposal ä»å¯¼è‡´ä¸€æ¬¡ WAL fsync
- æ— æ³•åˆ©ç”¨ Raft çš„æ‰¹é‡æäº¤èƒ½åŠ›
- é«˜å¹¶å‘æ—¶ï¼Œfsync æˆä¸ºç»å¯¹ç“¶é¢ˆ

**ä¼˜åŒ–æ–¹æ¡ˆ 3.1: å®ç° BatchProposer**

```go
// BatchProposer æ‰¹é‡ææ¡ˆå™¨
type BatchProposer struct {
    proposeC    chan<- string
    batchSize   int
    batchTime   time.Duration
    buffer      []string
    mu          sync.Mutex
    flushTicker *time.Ticker
    stopC       chan struct{}
}

func NewBatchProposer(proposeC chan<- string, batchSize int, batchTime time.Duration) *BatchProposer {
    bp := &BatchProposer{
        proposeC:    proposeC,
        batchSize:   batchSize,
        batchTime:   batchTime,
        buffer:      make([]string, 0, batchSize),
        flushTicker: time.NewTicker(batchTime),
        stopC:       make(chan struct{}),
    }

    go bp.run()
    return bp
}

func (bp *BatchProposer) Propose(ctx context.Context, data string) error {
    bp.mu.Lock()
    bp.buffer = append(bp.buffer, data)
    shouldFlush := len(bp.buffer) >= bp.batchSize
    bp.mu.Unlock()

    // è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³åˆ·æ–°
    if shouldFlush {
        bp.flush()
    }

    return nil
}

func (bp *BatchProposer) run() {
    for {
        select {
        case <-bp.flushTicker.C:
            bp.flush()
        case <-bp.stopC:
            bp.flush() // æœ€åä¸€æ¬¡åˆ·æ–°
            return
        }
    }
}

func (bp *BatchProposer) flush() {
    bp.mu.Lock()
    if len(bp.buffer) == 0 {
        bp.mu.Unlock()
        return
    }

    // åˆå¹¶ä¸ºå•ä¸ª proposal
    batch := bp.buffer
    bp.buffer = make([]string, 0, bp.batchSize)
    bp.mu.Unlock()

    // âœ… æ‰¹é‡æäº¤ (å•æ¬¡ fsync!)
    batchData := strings.Join(batch, "\n")
    bp.proposeC <- batchData
}

func (bp *BatchProposer) Stop() {
    close(bp.stopC)
    bp.flushTicker.Stop()
}
```

**ä½¿ç”¨ç¤ºä¾‹**:

```go
// åˆ›å»ºæ‰¹é‡ææ¡ˆå™¨
batchProposer := NewBatchProposer(
    proposeC,
    100,              // æ‰¹é‡å¤§å°ï¼š100 ä¸ªæ“ä½œ
    5*time.Millisecond, // æ‰¹é‡æ—¶é—´ï¼š5ms
)

// ä½¿ç”¨æ‰¹é‡ææ¡ˆå™¨æ›¿ä»£ç›´æ¥å‘é€
func (m *Memory) PutWithLease(...) {
    // ...

    // âœ… ä½¿ç”¨æ‰¹é‡ææ¡ˆå™¨
    batchProposer.Propose(ctx, data)

    // ...
}
```

**æ€§èƒ½æå‡è®¡ç®—**:

å‡è®¾:
- å½“å‰: 50 å¹¶å‘å®¢æˆ·ç«¯ï¼Œæ¯ä¸ªæ“ä½œ 5ms (å•æ¬¡ fsync)
- ä¼˜åŒ–å: 100 ä¸ªæ“ä½œåˆå¹¶ä¸º 1 æ¬¡ fsync (5ms)

```
ä¼˜åŒ–å‰ QPS = 1000 / 5 Ã— 50 = 10,000 ops/sec
ä¼˜åŒ–å QPS = (1000 / 5) Ã— 100 = 20,000 ops/sec
æå‡ = 2x

ä½†å®é™…ä¸Šï¼Œæ‰¹é‡è¶Šå¤§ï¼Œæå‡è¶Šæ˜æ˜¾ï¼š
æ‰¹é‡ 100: 10x æå‡ â†’ 100,000 ops/sec (ç†è®º)
æ‰¹é‡ 1000: 100x æå‡ â†’ 1,000,000 ops/sec (ç†è®º)

å®é™…å—é™äºå…¶ä»–ç“¶é¢ˆï¼Œé¢„æœŸ 5-10x æå‡
```

**é¢„æœŸæå‡**: +500-1000% â­â­â­â­â­

---

#### 3.2 å¼‚æ­¥ WAL å†™å…¥ (Async WAL)

**å½“å‰çŠ¶æ€**: åŒæ­¥ fsyncï¼Œæ¯æ¬¡ 2-5ms

**ä¼˜åŒ–æ–¹æ¡ˆ 3.2: Group Commit (ç»„æäº¤)**

```go
// WAL ç»„æäº¤å™¨
type GroupCommitWAL struct {
    wal         *wal.WAL
    commitQueue chan *CommitRequest
    batchSize   int
    batchTime   time.Duration
}

type CommitRequest struct {
    entry   raftpb.Entry
    resultC chan error
}

func NewGroupCommitWAL(w *wal.WAL, batchSize int, batchTime time.Duration) *GroupCommitWAL {
    gc := &GroupCommitWAL{
        wal:         w,
        commitQueue: make(chan *CommitRequest, 10000),
        batchSize:   batchSize,
        batchTime:   batchTime,
    }

    go gc.run()
    return gc
}

func (gc *GroupCommitWAL) Save(entry raftpb.Entry) error {
    req := &CommitRequest{
        entry:   entry,
        resultC: make(chan error, 1),
    }

    gc.commitQueue <- req
    return <-req.resultC // ç­‰å¾…ç»“æœ
}

func (gc *GroupCommitWAL) run() {
    ticker := time.NewTicker(gc.batchTime)
    defer ticker.Stop()

    batch := make([]*CommitRequest, 0, gc.batchSize)

    for {
        select {
        case req := <-gc.commitQueue:
            batch = append(batch, req)

            // è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³æäº¤
            if len(batch) >= gc.batchSize {
                gc.commitBatch(batch)
                batch = batch[:0]
            }

        case <-ticker.C:
            // è¶…æ—¶ï¼Œæäº¤å½“å‰æ‰¹æ¬¡
            if len(batch) > 0 {
                gc.commitBatch(batch)
                batch = batch[:0]
            }
        }
    }
}

func (gc *GroupCommitWAL) commitBatch(batch []*CommitRequest) {
    // âœ… æ‰¹é‡å†™å…¥ WAL (å•æ¬¡ fsync)
    entries := make([]raftpb.Entry, len(batch))
    for i, req := range batch {
        entries[i] = req.entry
    }

    // å•æ¬¡ fsync æäº¤æ‰€æœ‰
    err := gc.wal.SaveEntries(entries)

    // é€šçŸ¥æ‰€æœ‰ç­‰å¾…çš„è¯·æ±‚
    for _, req := range batch {
        req.resultC <- err
    }
}
```

**é¢„æœŸæå‡**: +300-500% (ä¸ BatchProposer å åŠ æ•ˆæœ)

---

#### 3.3 Raft Pipeline (æµæ°´çº¿åŒ–)

**ä¼˜åŒ–æ–¹æ¡ˆ 3.3: Raft AppendEntries æµæ°´çº¿**

Raft æ—¥å¿—å¤åˆ¶å¯ä»¥æµæ°´çº¿åŒ–ï¼Œä¸å¿…ç­‰å¾…å‰ä¸€ä¸ª AppendEntries å“åº”ï¼š

```go
// Raft é…ç½®ä¼˜åŒ–
raftCfg := &raft.Config{
    ID:                        uint64(rc.id),
    ElectionTick:              10,
    HeartbeatTick:             1,
    Storage:                   rc.raftStorage,
    MaxSizePerMsg:             1024 * 1024 * 10,    // 10MB æ¶ˆæ¯å¤§å°
    MaxCommittedSizePerReady:  512 * 1024 * 1024,  // 512MB æ¯æ¬¡æäº¤
    MaxUncommittedEntriesSize: 1024 * 1024 * 1024, // 1GB æœªæäº¤æ—¥å¿—
    MaxInflightMsgs:           256,                 // âœ… æµæ°´çº¿æ·±åº¦ï¼š256
    CheckQuorum:               true,
    PreVote:                   true,
    ReadOnlyOption:            raft.ReadOnlySafe,
    Logger:                    rc.logger,
}
```

**é¢„æœŸæå‡**: +50-100% (å¤šèŠ‚ç‚¹é›†ç¾¤åœºæ™¯)

---

### Layer 4: å­˜å‚¨å±‚ä¼˜åŒ– (Storage Layer)

#### 4.1 Memory å¼•æ“ä¼˜åŒ–

**4.1.1 WriteBatch æ‰¹é‡åº”ç”¨**

**å½“å‰çŠ¶æ€** ([internal/memory/kvstore.go:110-150](../internal/memory/kvstore.go#L110-L150)):
```go
// é€ä¸ªåº”ç”¨æ“ä½œ
for _, data := range commit.Data {
    var op RaftOperation
    json.Unmarshal([]byte(data), &op)
    m.applyOperation(op)  // æ¯æ¬¡éƒ½åŠ é”
}
```

**ä¼˜åŒ–æ–¹æ¡ˆ 4.1.1**: å·²åœ¨å‰é¢ MEMORY_STORAGE_PERFORMANCE_ANALYSIS.md ä¸­è¯¦ç»†è¯´æ˜

```go
func (m *Memory) applyOperationsBatch(ops []*RaftOperation) {
    m.MemoryEtcd.txnMu.Lock()  // âœ… å•æ¬¡åŠ é”
    defer m.MemoryEtcd.txnMu.Unlock()

    var watchEvents []kvstore.WatchEvent

    // æ‰¹é‡å¤„ç†
    for _, op := range ops {
        switch op.Type {
        case "PUT":
            rev, prevKv, _ := m.MemoryEtcd.putUnlocked(op.Key, op.Value, op.LeaseID)
            watchEvents = append(watchEvents, ...)
        }
    }

    // æ‰¹é‡é€šçŸ¥
    for _, event := range watchEvents {
        m.notifyWatches(event)
    }
}
```

**é¢„æœŸæå‡**: +200-300%

---

**4.1.2 ä½¿ç”¨ BTree åŠ é€Ÿ Range æŸ¥è¯¢**

**å½“å‰é—®é¢˜**: HashMap éœ€è¦ O(n) å…¨è¡¨æ‰«æ + æ’åº

**ä¼˜åŒ–æ–¹æ¡ˆ 4.1.2**:

```go
import "github.com/google/btree"

type MemoryEtcd struct {
    // åŒç´¢å¼•ç»“æ„
    kvData       *ShardedMap          // ä¸»ç´¢å¼•ï¼šå¿«é€Ÿç‚¹æŸ¥
    kvIndex      *btree.BTree         // è¾…åŠ©ç´¢å¼•ï¼šRange æŸ¥è¯¢

    indexMu      sync.RWMutex         // ä¿æŠ¤ BTree
    // ...
}

type btreeItem struct {
    key string
    kv  *kvstore.KeyValue
}

func (item *btreeItem) Less(than btree.Item) bool {
    return item.key < than.(*btreeItem).key
}

func (m *MemoryEtcd) Range(ctx context.Context, key, rangeEnd string, limit int64, revision int64) (*kvstore.RangeResponse, error) {
    m.indexMu.RLock()
    defer m.indexMu.RUnlock()

    kvs := make([]*kvstore.KeyValue, 0, limit)

    // âœ… O(log n) å®šä½ + O(m) éå†
    m.kvIndex.AscendGreaterOrEqual(&btreeItem{key: key}, func(item btree.Item) bool {
        kv := item.(*btreeItem).kv
        k := string(kv.Key)

        if rangeEnd != "\x00" && k >= rangeEnd {
            return false
        }

        kvs = append(kvs, kv)

        if limit > 0 && int64(len(kvs)) >= limit {
            return false
        }

        return true
    })

    // âœ… æ— éœ€æ’åºï¼
    return &kvstore.RangeResponse{
        Kvs:   kvs,
        More:  false,
        Count: int64(len(kvs)),
    }, nil
}
```

**é¢„æœŸæå‡**: Range æŸ¥è¯¢ +500-1000%

---

#### 4.2 RocksDB å¼•æ“ä¼˜åŒ–

**4.2.1 RocksDB é…ç½®è°ƒä¼˜**

```go
// ä¼˜åŒ– RocksDB é…ç½®
opts := grocksdb.NewDefaultOptions()

// 1. å†…å­˜ä¼˜åŒ–
opts.SetAllowConcurrentMemtableWrites(true)  // å¹¶å‘ memtable å†™å…¥
opts.SetWriteBufferSize(128 * 1024 * 1024)   // 128MB write buffer
opts.SetMaxWriteBufferNumber(4)              // 4 ä¸ª write buffer
opts.SetMinWriteBufferNumberToMerge(2)       // åˆå¹¶ 2 ä¸ª buffer

// 2. Block Cache (çƒ­æ•°æ®ç¼“å­˜)
blockCache := grocksdb.NewLRUCache(2 * 1024 * 1024 * 1024) // 2GB cache
blockOpts := grocksdb.NewDefaultBlockBasedTableOptions()
blockOpts.SetBlockCache(blockCache)
blockOpts.SetBlockSize(64 * 1024)            // 64KB block
blockOpts.SetCacheIndexAndFilterBlocks(true) // ç¼“å­˜ç´¢å¼•å’Œè¿‡æ»¤å™¨
opts.SetBlockBasedTableFactory(blockOpts)

// 3. Compaction ä¼˜åŒ–
opts.SetMaxBackgroundCompactions(4)          // 4 ä¸ªåå°å‹ç¼©çº¿ç¨‹
opts.SetMaxBackgroundFlushes(2)              // 2 ä¸ªåˆ·ç›˜çº¿ç¨‹
opts.SetLevel0FileNumCompactionTrigger(4)    // L0 4 ä¸ªæ–‡ä»¶è§¦å‘å‹ç¼©
opts.SetLevel0SlowdownWritesTrigger(20)      // L0 20 ä¸ªæ–‡ä»¶å‡é€Ÿ
opts.SetLevel0StopWritesTrigger(36)          // L0 36 ä¸ªæ–‡ä»¶åœæ­¢å†™å…¥

// 4. Bloom Filter (åŠ é€ŸæŸ¥æ‰¾)
opts.SetBloomFilterBitsPerKey(10)            // 10 bits/key bloom filter

// 5. Compression (å‹ç¼©ç­–ç•¥)
opts.SetCompressionType(grocksdb.LZ4Compression) // L0-L2 ä½¿ç”¨ LZ4
opts.SetBottommostCompressionType(grocksdb.ZSTDCompression) // L3+ ä½¿ç”¨ ZSTD

// 6. WAL ä¼˜åŒ–
opts.SetMaxTotalWalSize(512 * 1024 * 1024)   // 512MB WAL ä¸Šé™

// 7. å†™å…¥ä¼˜åŒ–
writeOpts := grocksdb.NewDefaultWriteOptions()
writeOpts.SetSync(false)                      // âœ… å¼‚æ­¥å†™å…¥ (ä¾èµ– Raft WAL)
writeOpts.DisableWAL(true)                    // âœ… ç¦ç”¨ RocksDB WAL (å·²æœ‰ Raft WAL)
```

**é¢„æœŸæå‡**: +50-100%

---

**4.2.2 WriteBatch ä¼˜åŒ– (å·²å®ç°)**

RocksDB å·²ä½¿ç”¨ WriteBatchï¼Œä½†å¯è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š

```go
// å¢å¤§ WriteBatch å®¹é‡
func (r *RocksDB) applyOperationsBatch(ops []*RaftOperation) {
    // é¢„åˆ†é…å®¹é‡
    batch := grocksdb.NewWriteBatchWithReservedBytes(len(ops) * 256) // æ¯ä¸ªæ“ä½œçº¦ 256 bytes
    defer batch.Destroy()

    // æ‰¹é‡æ·»åŠ 
    for _, op := range ops {
        switch op.Type {
        case "PUT":
            r.preparePutBatch(batch, op.Key, op.Value, op.LeaseID)
        case "DELETE":
            r.prepareDeleteBatch(batch, op.Key, op.RangeEnd)
        }
    }

    // âœ… å•æ¬¡å†™å…¥
    if err := r.db.Write(r.wo, batch); err != nil {
        log.Errorf("Batch write failed: %v", err)
    }
}
```

**é¢„æœŸæå‡**: +20-30%

---

### Layer 5: æ•°æ®ç»“æ„å±‚ä¼˜åŒ–

#### 5.1 æ— é”æ•°æ®ç»“æ„

**ä¼˜åŒ–æ–¹æ¡ˆ 5.1: Lock-Free ShardedMap**

ä½¿ç”¨åŸå­æ“ä½œå’Œ CAS (Compare-And-Swap) å®ç°æ— é”åˆ†ç‰‡ mapï¼š

```go
import "sync/atomic"

type LockFreeShardedMap struct {
    shards [256]*LockFreeShard
}

type LockFreeShard struct {
    head atomic.Pointer[Node]  // ä½¿ç”¨é“¾è¡¨ + CAS
}

type Node struct {
    key   string
    value *kvstore.KeyValue
    next  atomic.Pointer[Node]
    hash  uint32
}

func (s *LockFreeShard) Set(key string, value *kvstore.KeyValue) {
    newNode := &Node{
        key:   key,
        value: value,
        hash:  hash(key),
    }

    for {
        oldHead := s.head.Load()
        newNode.next.Store(oldHead)

        // âœ… CAS æ“ä½œï¼Œæ— é”
        if s.head.CompareAndSwap(oldHead, newNode) {
            return
        }
        // å¤±è´¥åˆ™é‡è¯•
    }
}

func (s *LockFreeShard) Get(key string) (*kvstore.KeyValue, bool) {
    h := hash(key)
    node := s.head.Load()

    for node != nil {
        if node.hash == h && node.key == key {
            return node.value, true
        }
        node = node.next.Load()
    }

    return nil, false
}
```

**æ³¨æ„**: Lock-Free å®ç°å¤æ‚ï¼Œå»ºè®®å…ˆåšå…¶ä»–ä¼˜åŒ–

**é¢„æœŸæå‡**: +50-100% (è¯»å¯†é›†åœºæ™¯)

---

#### 5.2 é›¶æ‹·è´ (Zero-Copy)

**ä¼˜åŒ–æ–¹æ¡ˆ 5.2: ä½¿ç”¨ bytes.Buffer æ± **

```go
var bufferPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func (m *Memory) PutWithLease(...) {
    // âœ… ä»æ± ä¸­è·å– buffer
    buf := bufferPool.Get().(*bytes.Buffer)
    buf.Reset()
    defer bufferPool.Put(buf)

    // åºåˆ—åŒ–åˆ° buffer
    encoder := json.NewEncoder(buf)
    encoder.Encode(op)

    // å¤ç”¨ buffer
    m.proposeC <- buf.String()
}
```

**é¢„æœŸæå‡**: +10-20% (å‡å°‘ GC å‹åŠ›)

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¼˜åŒ–è·¯çº¿å›¾

### Phase 1: å¿«é€Ÿä¼˜åŒ– (2 å‘¨) - ç›®æ ‡ 20K QPS

**ä¼˜å…ˆçº§**: â­â­â­â­â­

| ä¼˜åŒ–é¡¹ | å±‚çº§ | é¢„æœŸæå‡ | å·¥ä½œé‡ | é£é™© |
|-------|------|---------|--------|------|
| **3.1 BatchProposer** | Raft | +500% | 3å¤© | ä¸­ |
| **2.2 Protobuf åºåˆ—åŒ–** | Protocol | +50% | 2å¤© | ä½ |
| **4.1.1 WriteBatch** | Storage | +200% | 3å¤© | ä¸­ |
| **1.1 gRPC å¹¶å‘ä¼˜åŒ–** | Network | +30% | 1å¤© | ä½ |

**ç´¯è®¡æå‡**: 3,386 Ã— 6 â‰ˆ **20,000 QPS** âœ…

---

### Phase 2: ç»“æ„ä¼˜åŒ– (4 å‘¨) - ç›®æ ‡ 50K QPS

**ä¼˜å…ˆçº§**: â­â­â­â­

| ä¼˜åŒ–é¡¹ | å±‚çº§ | é¢„æœŸæå‡ | å·¥ä½œé‡ | é£é™© |
|-------|------|---------|--------|------|
| **3.2 Group Commit WAL** | Raft | +300% | 5å¤© | é«˜ |
| **4.1.2 BTree Index** | Storage | +500% (Range) | 5å¤© | ä¸­ |
| **2.1 Batch API** | Protocol | +200% (Batch) | 3å¤© | ä½ |
| **4.2.1 RocksDB è°ƒä¼˜** | Storage | +50% | 2å¤© | ä½ |

**ç´¯è®¡æå‡**: 20,000 Ã— 2.5 â‰ˆ **50,000 QPS** âœ…

---

### Phase 3: æè‡´ä¼˜åŒ– (6 å‘¨) - ç›®æ ‡ 100K+ QPS

**ä¼˜å…ˆçº§**: â­â­â­

| ä¼˜åŒ–é¡¹ | å±‚çº§ | é¢„æœŸæå‡ | å·¥ä½œé‡ | é£é™© |
|-------|------|---------|--------|------|
| **3.3 Raft Pipeline** | Raft | +100% | 5å¤© | é«˜ |
| **5.1 Lock-Free Map** | Data Structures | +50% | 10å¤© | é«˜ |
| **1.2 è¿æ¥æ± ä¼˜åŒ–** | Network | +50% | 3å¤© | ä½ |
| **5.2 Zero-Copy** | Data Structures | +20% | 3å¤© | ä¸­ |

**ç´¯è®¡æå‡**: 50,000 Ã— 2 â‰ˆ **100,000 QPS** âœ…

---

### Phase 4: é›†ç¾¤ä¼˜åŒ– (8 å‘¨) - ç›®æ ‡ 300K+ QPS

**ä¼˜å…ˆçº§**: â­â­

| ä¼˜åŒ–é¡¹ | å±‚çº§ | é¢„æœŸæå‡ | å·¥ä½œé‡ | é£é™© |
|-------|------|---------|--------|------|
| Follower è¯»å– | Raft | +200% | 10å¤© | ä¸­ |
| åˆ†åŒº/Sharding | Architecture | +300% | 20å¤© | é«˜ |
| è¯»å†™åˆ†ç¦» | Architecture | +100% | 10å¤© | ä¸­ |

**ç´¯è®¡æå‡**: 100,000 Ã— 3 â‰ˆ **300,000 QPS** âœ…

---

### Phase 5: ç”Ÿäº§çº§ä¼˜åŒ– (æŒç»­) - ç›®æ ‡ 1M+ QPS

**ä¼˜å…ˆçº§**: â­

- è‡ªé€‚åº”æ‰¹é‡å¤§å°
- æ™ºèƒ½ç¼“å­˜é¢„å–
- NUMA ä¼˜åŒ–
- DPDK ç½‘ç»œåŠ é€Ÿ
- GPU åŠ é€Ÿåºåˆ—åŒ–

---

## ç¬¬å››éƒ¨åˆ†ï¼šå®æ–½è®¡åˆ’

### 4.1 å®æ–½ä¼˜å…ˆçº§çŸ©é˜µ

```
é«˜å½±å“ â†‘
    â”‚
    â”‚  [3.1 BatchProposer]      [2.2 Protobuf]
    â”‚  [4.1.1 WriteBatch]
    â”‚
    â”‚  [3.2 GroupCommit]        [4.1.2 BTree]
    â”‚                           [2.1 Batch API]
    â”‚
    â”‚  [3.3 Pipeline]           [1.1 gRPCä¼˜åŒ–]
    â”‚  [5.1 Lock-Free]          [4.2 RocksDBè°ƒä¼˜]
    â”‚
    â”‚  [åˆ†åŒºSharding]            [1.2 è¿æ¥æ± ]
    â”‚                           [5.2 Zero-Copy]
    â”‚
ä½å½±å“ â†“â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
          ä½å·¥ä½œé‡              é«˜å·¥ä½œé‡
```

**ç­–ç•¥**: ä¼˜å…ˆå®æ–½å·¦ä¸Šè§’ (é«˜å½±å“ + ä½å·¥ä½œé‡) çš„ä¼˜åŒ–

---

### 4.2 Memory vs RocksDB ä¼˜åŒ–ç­–ç•¥

#### Memory å¼•æ“ä¼˜åŒ–é‡ç‚¹

| ä¼˜åŒ–é¡¹ | ä¼˜å…ˆçº§ | åŸå›  |
|-------|--------|------|
| BatchProposer | â­â­â­â­â­ | Raft ç“¶é¢ˆå¯¹ä¸¤è€…éƒ½é€‚ç”¨ |
| WriteBatch | â­â­â­â­â­ | Memory ç¼ºå°‘æ‰¹é‡å¤„ç† |
| BTree Index | â­â­â­â­ | Range æŸ¥è¯¢è¿œæ…¢äº RocksDB |
| Protobuf | â­â­â­â­ | åºåˆ—åŒ–å¼€é”€å¤§ |
| Lock-Free | â­â­â­ | è¿›ä¸€æ­¥å‡å°‘é”ç«äº‰ |

**ç›®æ ‡**: è®© Memory åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹è¶…è¶Š RocksDB

---

#### RocksDB å¼•æ“ä¼˜åŒ–é‡ç‚¹

| ä¼˜åŒ–é¡¹ | ä¼˜å…ˆçº§ | åŸå›  |
|-------|--------|------|
| BatchProposer | â­â­â­â­â­ | Raft ç“¶é¢ˆå¯¹ä¸¤è€…éƒ½é€‚ç”¨ |
| é…ç½®è°ƒä¼˜ | â­â­â­â­ | æŒ–æ˜ RocksDB æ½œåŠ› |
| Protobuf | â­â­â­â­ | åºåˆ—åŒ–å¼€é”€å¤§ |
| ç¦ç”¨ RocksDB WAL | â­â­â­ | ä¾èµ– Raft WALï¼Œé¿å…åŒå†™ |
| Block Cache | â­â­â­ | æå‡è¯»æ€§èƒ½ |

**ç›®æ ‡**: ä¿æŒ RocksDB çš„æŒä¹…æ€§ä¼˜åŠ¿ï¼Œæå‡æ€§èƒ½

---

### 4.3 æµ‹è¯•ä¸éªŒè¯ç­–ç•¥

#### 4.3.1 åŸºå‡†æµ‹è¯•

æ¯æ¬¡ä¼˜åŒ–åï¼Œå¿…é¡»è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•ï¼š

```bash
# Memory å¼•æ“æ€§èƒ½æµ‹è¯•
make test-perf-memory

# RocksDB å¼•æ“æ€§èƒ½æµ‹è¯•
make test-perf-rocksdb

# å¯¹æ¯”æµ‹è¯•
./scripts/compare_performance.sh
```

#### 4.3.2 æ€§èƒ½å›å½’æµ‹è¯•

å»ºç«‹è‡ªåŠ¨åŒ–æ€§èƒ½å›å½’æµ‹è¯•ï¼š

```yaml
# .github/workflows/perf-regression.yml
name: Performance Regression Test

on:
  pull_request:
    branches: [main]

jobs:
  perf-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run baseline test
        run: |
          git checkout main
          make test-perf > baseline.txt

      - name: Run PR test
        run: |
          git checkout ${{ github.head_ref }}
          make test-perf > pr.txt

      - name: Compare results
        run: |
          ./scripts/compare_perf.sh baseline.txt pr.txt

      - name: Fail if regression > 10%
        run: |
          if [ $REGRESSION -gt 10 ]; then
            echo "Performance regression detected: $REGRESSION%"
            exit 1
          fi
```

---

### 4.4 é£é™©ç®¡ç†

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| **Raft WAL å¼‚æ­¥ä¸¢æ•°æ®** | ä¸­ | æé«˜ | ä½¿ç”¨ Group Commit è€Œéå®Œå…¨å¼‚æ­¥ |
| **Lock-Free å®ç° Bug** | é«˜ | é«˜ | å……åˆ†æµ‹è¯•ï¼Œä½¿ç”¨æˆç†Ÿåº“ |
| **æ€§èƒ½ä¼˜åŒ–å¼•å…¥ Bug** | ä¸­ | é«˜ | ä¸¥æ ¼æµ‹è¯•ï¼Œåˆ†é˜¶æ®µä¸Šçº¿ |
| **é…ç½®è°ƒä¼˜é€‚å¾—å…¶å** | ä½ | ä¸­ | æ€§èƒ½æµ‹è¯•éªŒè¯ï¼Œä¿ç•™å›é€€æ–¹æ¡ˆ |
| **ä¾èµ–åº“ç‰ˆæœ¬å†²çª** | ä½ | ä¸­ | ç‰ˆæœ¬é”å®šï¼Œå…¼å®¹æ€§æµ‹è¯• |

---

## ç¬¬äº”éƒ¨åˆ†ï¼šç›‘æ§ä¸åº¦é‡

### 5.1 å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPI)

#### ååé‡æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | Phase 1 | Phase 2 | Phase 3 | æœ€ç»ˆç›®æ ‡ |
|-----|--------|---------|---------|---------|---------|
| **Memory QPS** | 3,386 | 20K | 50K | 100K | 100K+ |
| **RocksDB QPS** | 4,921 | 25K | 60K | 120K | 120K+ |
| **Batch QPS** | N/A | 50K | 150K | 300K | 300K+ |

#### å»¶è¿ŸæŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ |
|-----|--------|--------|
| **P50 å»¶è¿Ÿ** | 4 ms | < 2 ms |
| **P99 å»¶è¿Ÿ** | 10 ms | < 5 ms |
| **P999 å»¶è¿Ÿ** | 50 ms | < 20 ms |

#### èµ„æºä½¿ç”¨æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰å€¼ | ç›®æ ‡å€¼ |
|-----|--------|--------|
| **CPU ä½¿ç”¨ç‡** | 60% (4 æ ¸) | < 80% (4 æ ¸) |
| **å†…å­˜ä½¿ç”¨** | 500 MB | < 2 GB |
| **ç£ç›˜ IOPS** | 1K | < 10K |
| **ç½‘ç»œå¸¦å®½** | 10 Mbps | < 1 Gbps |

---

### 5.2 ç›‘æ§æŒ‡æ ‡å®šä¹‰

```yaml
# Prometheus æŒ‡æ ‡å®šä¹‰
metrics:
  - name: metastore_ops_total
    type: counter
    help: "Total operations processed"
    labels: [operation, storage_engine, status]

  - name: metastore_op_duration_seconds
    type: histogram
    help: "Operation latency distribution"
    labels: [operation, storage_engine]
    buckets: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]

  - name: metastore_raft_proposal_batch_size
    type: histogram
    help: "Raft proposal batch size"
    buckets: [1, 5, 10, 20, 50, 100, 200, 500]

  - name: metastore_wal_fsync_duration_seconds
    type: histogram
    help: "WAL fsync duration"
    buckets: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05]

  - name: metastore_storage_lock_wait_seconds
    type: histogram
    help: "Storage lock wait time"
    buckets: [0.0001, 0.0005, 0.001, 0.005, 0.01]
```

---

### 5.3 æ€§èƒ½ä»ªè¡¨æ¿

```yaml
# Grafana ä»ªè¡¨æ¿é…ç½®
dashboard:
  title: "MetaStore Performance Dashboard"

  panels:
    - title: "QPS (Operations/sec)"
      query: |
        rate(metastore_ops_total{status="success"}[1m])

    - title: "P99 Latency"
      query: |
        histogram_quantile(0.99,
          rate(metastore_op_duration_seconds_bucket[1m]))

    - title: "Raft Batch Size"
      query: |
        histogram_quantile(0.5,
          rate(metastore_raft_proposal_batch_size_bucket[1m]))

    - title: "WAL Fsync Duration"
      query: |
        histogram_quantile(0.99,
          rate(metastore_wal_fsync_duration_seconds_bucket[1m]))
```

---

## ç¬¬å…­éƒ¨åˆ†ï¼šæˆåŠŸæ ‡å‡†

### 6.1 åŠŸèƒ½è¦æ±‚

- âœ… æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡
- âœ… æ–°å¢æ€§èƒ½æµ‹è¯•è¦†ç›–æ‰€æœ‰ä¼˜åŒ–ç‚¹
- âœ… å…¼å®¹ etcd v3 API
- âœ… æ”¯æŒ Memory + RocksDB åŒå¼•æ“

### 6.2 æ€§èƒ½è¦æ±‚

- âœ… **Phase 1**: å•èŠ‚ç‚¹ QPS è¾¾åˆ° 20K+
- âœ… **Phase 2**: å•èŠ‚ç‚¹ QPS è¾¾åˆ° 50K+
- âœ… **Phase 3**: å•èŠ‚ç‚¹ QPS è¾¾åˆ° 100K+
- âœ… P99 å»¶è¿Ÿ < 5ms
- âœ… P999 å»¶è¿Ÿ < 20ms

### 6.3 ç¨³å®šæ€§è¦æ±‚

- âœ… 7Ã—24 å°æ—¶å‹æµ‹æ— å´©æºƒ
- âœ… é”™è¯¯ç‡ < 0.01%
- âœ… å†…å­˜æ³„æ¼æ£€æµ‹é€šè¿‡
- âœ… æ•°æ®ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡

---

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ€»ç»“

### 7.1 ä¼˜åŒ–ç­–ç•¥æ€»ç»“

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ ¸å¿ƒç­–ç•¥ï¼šåˆ†å±‚æ‰¹é‡åŒ– (Layered Batching)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3 (Raft): æ‰¹é‡ Proposal + Group Commit â†’ 5-10x         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2 (Protocol): Protobuf + Batch API â†’ 2-3x              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4 (Storage): WriteBatch + BTree â†’ 2-3x                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1 (Network): gRPC ä¼˜åŒ– + è¿æ¥æ±  â†’ 1.5-2x               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5 (Data Structures): Lock-Free + Zero-Copy â†’ 1.5-2x    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
æ€»æå‡: 5 Ã— 2.5 Ã— 2.5 Ã— 1.75 Ã— 1.75 â‰ˆ 96x (ç†è®º)
ä¿å®ˆä¼°è®¡: ~25-30x â†’ 100K+ QPS âœ…
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 7.2 å…³é”®è¦ç‚¹

1. **Raft WAL æ˜¯ç»å¯¹ç“¶é¢ˆ** (50-70% å»¶è¿Ÿ)
   - æ‰¹é‡ææ¡ˆ (BatchProposer) æ˜¯**æ ¸å¿ƒä¼˜åŒ–** â­â­â­â­â­
   - Group Commit è¿›ä¸€æ­¥å‡å°‘ fsync æ¬¡æ•°

2. **åºåˆ—åŒ–å¼€é”€ä¸å®¹å¿½è§†** (15-20% CPU)
   - Protobuf æ¯” JSON å¿« 3-5x
   - å€¼å¾—è¿ç§»

3. **Memory å¼•æ“æœ‰å·¨å¤§æ½œåŠ›**
   - WriteBatch + BTree å¯è¶…è¶Š RocksDB
   - é€‚åˆé«˜å¹¶å‘ç¼“å­˜åœºæ™¯

4. **RocksDB éœ€è¦ç²¾ç»†è°ƒä¼˜**
   - Block Cacheã€Bloom Filterã€Compaction
   - ç¦ç”¨ RocksDB WAL (ä¾èµ– Raft WAL)

5. **åˆ†å±‚ä¼˜åŒ–ï¼Œé€æ­¥æ¨è¿›**
   - å…ˆåšé«˜ ROI ä¼˜åŒ– (BatchProposer)
   - ååšç»“æ„æ€§ä¼˜åŒ– (BTree, Lock-Free)
   - æœ€åè€ƒè™‘é›†ç¾¤ä¼˜åŒ– (Sharding, åˆ†åŒº)

---

### 7.3 ä¸‹ä¸€æ­¥è¡ŒåŠ¨

#### ç«‹å³å¼€å§‹ (æœ¬å‘¨)

1. **åˆ›å»ºæ€§èƒ½åŸºçº¿** - è¯¦ç»†æµ‹é‡å½“å‰å„å±‚å»¶è¿Ÿ
2. **å®ç° BatchProposer** - 3 å¤© MVP
3. **Protobuf åºåˆ—åŒ–** - 2 å¤©è¿ç§»

#### 2 å‘¨å†…å®Œæˆ

4. **WriteBatch (Memory)** - 3 å¤©å®ç°
5. **gRPC å¹¶å‘ä¼˜åŒ–** - 1 å¤©é…ç½®

**ç›®æ ‡**: 2 å‘¨å†…è¾¾åˆ° **20K QPS** âœ…

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ
**æœ€åæ›´æ–°**: 2025-11-01
**è´Ÿè´£äºº**: æ€§èƒ½ä¼˜åŒ–å›¢é˜Ÿ
**å®¡æ ¸**: CTO

---

## é™„å½•

### A. å‚è€ƒèµ„æ–™

1. **etcd Performance Tuning**
   - https://etcd.io/docs/v3.5/tuning/

2. **Raft Optimization Papers**
   - "In Search of an Understandable Consensus Algorithm" (Raft Paper)
   - "Paxos Made Live" (Google Chubby)

3. **RocksDB Tuning Guide**
   - https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide

4. **gRPC Performance Best Practices**
   - https://grpc.io/docs/guides/performance/

### B. æ€§èƒ½æµ‹è¯•å·¥å…·

```bash
# 1. åŸºå‡†æµ‹è¯•
go test -bench=. -benchmem -benchtime=10s ./test

# 2. CPU æ€§èƒ½åˆ†æ
go test -cpuprofile=cpu.prof -bench=. ./test
go tool pprof cpu.prof

# 3. å†…å­˜åˆ†æ
go test -memprofile=mem.prof -bench=. ./test
go tool pprof mem.prof

# 4. ç«ç„°å›¾
go test -cpuprofile=cpu.prof -bench=. ./test
go tool pprof -http=:8080 cpu.prof

# 5. å‹åŠ›æµ‹è¯•
./scripts/stress_test.sh --qps 100000 --duration 1h
```

### C. ä»£ç ç¤ºä¾‹ä»“åº“

å®Œæ•´ä¼˜åŒ–ä»£ç ç¤ºä¾‹ï¼š`examples/performance-optimization/`

---

**è®©æˆ‘ä»¬ä¸€èµ·å°† MetaStore æ‰“é€ æˆä¸–ç•Œçº§çš„é«˜æ€§èƒ½å…ƒæ•°æ®å­˜å‚¨ç³»ç»Ÿï¼** ğŸš€
